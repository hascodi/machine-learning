<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Hoofdstuk 9 Autoencoders | Machine Learning</title>
  <meta name="description" content="Artificial intelligence course at the AP University College." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Hoofdstuk 9 Autoencoders | Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Artificial intelligence course at the AP University College." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Hoofdstuk 9 Autoencoders | Machine Learning" />
  
  <meta name="twitter:description" content="Artificial intelligence course at the AP University College." />
  

<meta name="author" content="34142/1916/2021/1/38 David Dâ€™Haese" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />
<link rel="prev" href="convolutionele-neurale-netwerken-cnn.html"/>
<link rel="next" href="trainen-en-testen.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\course.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="inleiding-tot-de-cursus.html"><a href="inleiding-tot-de-cursus.html"><i class="fa fa-check"></i><b>1</b> Inleiding tot de cursus</a><ul>
<li class="chapter" data-level="1.1" data-path="inleiding-tot-de-cursus.html"><a href="inleiding-tot-de-cursus.html#in-een-notedop"><i class="fa fa-check"></i><b>1.1</b> In een notedop</a></li>
<li class="chapter" data-level="1.2" data-path="inleiding-tot-de-cursus.html"><a href="inleiding-tot-de-cursus.html#leerdoelen"><i class="fa fa-check"></i><b>1.2</b> Leerdoelen</a></li>
<li class="chapter" data-level="1.3" data-path="inleiding-tot-de-cursus.html"><a href="inleiding-tot-de-cursus.html#cursus-vorm"><i class="fa fa-check"></i><b>1.3</b> Cursus vorm</a></li>
<li class="chapter" data-level="1.4" data-path="inleiding-tot-de-cursus.html"><a href="inleiding-tot-de-cursus.html#bekijken-van-deze-cursus"><i class="fa fa-check"></i><b>1.4</b> Bekijken van deze Cursus</a></li>
<li class="chapter" data-level="1.5" data-path="inleiding-tot-de-cursus.html"><a href="inleiding-tot-de-cursus.html#code-uit-de-cursus-uitvoeren"><i class="fa fa-check"></i><b>1.5</b> Code uit de cursus uitvoeren</a></li>
<li class="chapter" data-level="1.6" data-path="inleiding-tot-de-cursus.html"><a href="inleiding-tot-de-cursus.html#oefeningen-maken"><i class="fa fa-check"></i><b>1.6</b> Oefeningen maken</a></li>
<li class="chapter" data-level="1.7" data-path="inleiding-tot-de-cursus.html"><a href="inleiding-tot-de-cursus.html#licentie-voor-deze-cursus"><i class="fa fa-check"></i><b>1.7</b> Licentie voor deze cursus</a></li>
<li class="chapter" data-level="1.8" data-path="inleiding-tot-de-cursus.html"><a href="inleiding-tot-de-cursus.html#verwijzen-naar-deze-cursus"><i class="fa fa-check"></i><b>1.8</b> Verwijzen naar deze cursus</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="leren-uit-data.html"><a href="leren-uit-data.html"><i class="fa fa-check"></i><b>2</b> Leren uit data</a><ul>
<li class="chapter" data-level="2.1" data-path="leren-uit-data.html"><a href="leren-uit-data.html#het-leerproces"><i class="fa fa-check"></i><b>2.1</b> Het leerproces</a></li>
<li class="chapter" data-level="2.2" data-path="leren-uit-data.html"><a href="leren-uit-data.html#de-evolutie-van-het-machinaal-leren"><i class="fa fa-check"></i><b>2.2</b> De evolutie van het machinaal leren</a></li>
<li class="chapter" data-level="2.3" data-path="leren-uit-data.html"><a href="leren-uit-data.html#intelligentie"><i class="fa fa-check"></i><b>2.3</b> Intelligentie</a></li>
<li class="chapter" data-level="2.4" data-path="leren-uit-data.html"><a href="leren-uit-data.html#het-model"><i class="fa fa-check"></i><b>2.4</b> Het model</a></li>
<li class="chapter" data-level="2.5" data-path="leren-uit-data.html"><a href="leren-uit-data.html#doelfunctie"><i class="fa fa-check"></i><b>2.5</b> Doelfunctie</a></li>
<li class="chapter" data-level="2.6" data-path="leren-uit-data.html"><a href="leren-uit-data.html#mnist-dataset"><i class="fa fa-check"></i><b>2.6</b> MNIST dataset</a></li>
<li class="chapter" data-level="2.7" data-path="leren-uit-data.html"><a href="leren-uit-data.html#het-resultaat-van-mnist-analyse"><i class="fa fa-check"></i><b>2.7</b> Het resultaat van MNIST analyse</a></li>
<li class="chapter" data-level="2.8" data-path="leren-uit-data.html"><a href="leren-uit-data.html#het-mnist-model"><i class="fa fa-check"></i><b>2.8</b> Het MNIST model</a></li>
<li class="chapter" data-level="2.9" data-path="leren-uit-data.html"><a href="leren-uit-data.html#het-leerproces-voor-begeleid-ml"><i class="fa fa-check"></i><b>2.9</b> Het leerproces voor begeleid ML</a></li>
<li class="chapter" data-level="2.10" data-path="leren-uit-data.html"><a href="leren-uit-data.html#de-onderdelen-van-een-model"><i class="fa fa-check"></i><b>2.10</b> De onderdelen van een model</a></li>
<li class="chapter" data-level="2.11" data-path="leren-uit-data.html"><a href="leren-uit-data.html#hyperparameters"><i class="fa fa-check"></i><b>2.11</b> Hyperparameters</a></li>
<li class="chapter" data-level="2.12" data-path="leren-uit-data.html"><a href="leren-uit-data.html#het-leeralgoritme"><i class="fa fa-check"></i><b>2.12</b> Het leeralgoritme</a></li>
<li class="chapter" data-level="2.13" data-path="leren-uit-data.html"><a href="leren-uit-data.html#model-complexiteit"><i class="fa fa-check"></i><b>2.13</b> Model complexiteit</a></li>
<li class="chapter" data-level="2.14" data-path="leren-uit-data.html"><a href="leren-uit-data.html#comprimeren-door-middel-van-een-ml-model"><i class="fa fa-check"></i><b>2.14</b> Comprimeren door middel van een ML model</a></li>
<li class="chapter" data-level="2.15" data-path="leren-uit-data.html"><a href="leren-uit-data.html#leren-versus-ontwerp"><i class="fa fa-check"></i><b>2.15</b> Leren versus ontwerp</a></li>
<li class="chapter" data-level="2.16" data-path="leren-uit-data.html"><a href="leren-uit-data.html#leren-versus-onthouden-en-inferentie"><i class="fa fa-check"></i><b>2.16</b> Leren versus onthouden en inferentie</a></li>
<li class="chapter" data-level="2.17" data-path="leren-uit-data.html"><a href="leren-uit-data.html#onbegeleid-ml"><i class="fa fa-check"></i><b>2.17</b> Onbegeleid ML</a></li>
<li class="chapter" data-level="2.18" data-path="leren-uit-data.html"><a href="leren-uit-data.html#conditionering"><i class="fa fa-check"></i><b>2.18</b> Conditionering</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Data</a><ul>
<li class="chapter" data-level="3.1" data-path="data.html"><a href="data.html#data-voor-ml"><i class="fa fa-check"></i><b>3.1</b> Data voor ML</a></li>
<li class="chapter" data-level="3.2" data-path="data.html"><a href="data.html#wat-is-data"><i class="fa fa-check"></i><b>3.2</b> Wat is data</a></li>
<li class="chapter" data-level="3.3" data-path="data.html"><a href="data.html#soorten-data"><i class="fa fa-check"></i><b>3.3</b> Soorten data</a></li>
<li class="chapter" data-level="3.4" data-path="data.html"><a href="data.html#externe-databronnen"><i class="fa fa-check"></i><b>3.4</b> Externe databronnen</a></li>
<li class="chapter" data-level="3.5" data-path="data.html"><a href="data.html#data-genereren"><i class="fa fa-check"></i><b>3.5</b> Data Genereren</a></li>
<li class="chapter" data-level="3.6" data-path="data.html"><a href="data.html#de-analyse-dataset"><i class="fa fa-check"></i><b>3.6</b> De analyse dataset</a></li>
<li class="chapter" data-level="3.7" data-path="data.html"><a href="data.html#soorten-variabelen"><i class="fa fa-check"></i><b>3.7</b> Soorten variabelen</a></li>
<li class="chapter" data-level="3.8" data-path="data.html"><a href="data.html#eng-nominal-scale-data"><i class="fa fa-check"></i><b>3.8</b> (Eng) Nominal-Scale Data</a></li>
<li class="chapter" data-level="3.9" data-path="data.html"><a href="data.html#eng-dummy-variables"><i class="fa fa-check"></i><b>3.9</b> (Eng) Dummy Variables</a></li>
<li class="chapter" data-level="3.10" data-path="data.html"><a href="data.html#eng-ordinal-scale-data"><i class="fa fa-check"></i><b>3.10</b> (Eng) Ordinal-Scale Data</a></li>
<li class="chapter" data-level="3.11" data-path="data.html"><a href="data.html#eng-circular-scale"><i class="fa fa-check"></i><b>3.11</b> (Eng) Circular-Scale</a></li>
<li class="chapter" data-level="3.12" data-path="data.html"><a href="data.html#eng-censoring"><i class="fa fa-check"></i><b>3.12</b> (Eng) Censoring</a></li>
<li class="chapter" data-level="3.13" data-path="data.html"><a href="data.html#tijd-en-ruimte"><i class="fa fa-check"></i><b>3.13</b> Tijd en ruimte</a></li>
<li class="chapter" data-level="3.14" data-path="data.html"><a href="data.html#toegang-tot-data"><i class="fa fa-check"></i><b>3.14</b> Toegang tot data</a></li>
<li class="chapter" data-level="3.15" data-path="data.html"><a href="data.html#het-codeboek"><i class="fa fa-check"></i><b>3.15</b> Het codeboek</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-exploratie.html"><a href="data-exploratie.html"><i class="fa fa-check"></i><b>4</b> Data exploratie</a><ul>
<li class="chapter" data-level="4.1" data-path="data-exploratie.html"><a href="data-exploratie.html#principes-van-data-exploratie"><i class="fa fa-check"></i><b>4.1</b> Principes van data exploratie</a></li>
<li class="chapter" data-level="4.2" data-path="data-exploratie.html"><a href="data-exploratie.html#stappen-in-data-exploratie"><i class="fa fa-check"></i><b>4.2</b> Stappen in data exploratie</a></li>
<li class="chapter" data-level="4.3" data-path="data-exploratie.html"><a href="data-exploratie.html#voorbeeld-data-exploratie"><i class="fa fa-check"></i><b>4.3</b> Voorbeeld data exploratie</a></li>
<li class="chapter" data-level="4.4" data-path="data-exploratie.html"><a href="data-exploratie.html#univariate-verdelingen"><i class="fa fa-check"></i><b>4.4</b> Univariate verdelingen</a></li>
<li class="chapter" data-level="4.5" data-path="data-exploratie.html"><a href="data-exploratie.html#correlatie-tussen-twee-variabelen"><i class="fa fa-check"></i><b>4.5</b> Correlatie tussen twee variabelen</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html"><i class="fa fa-check"></i><b>5</b> Manipuleren van data</a><ul>
<li class="chapter" data-level="5.1" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#kort-overzicht-van-de-manipulaties"><i class="fa fa-check"></i><b>5.1</b> Kort overzicht van de manipulaties</a><ul>
<li class="chapter" data-level="5.1.1" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#filteren-en-versnijden"><i class="fa fa-check"></i><b>5.1.1</b> Filteren en versnijden</a></li>
<li class="chapter" data-level="5.1.2" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#booleaans-masker"><i class="fa fa-check"></i><b>5.1.2</b> Booleaans masker</a></li>
<li class="chapter" data-level="5.1.3" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#eng.-grouping-and-aggregation"><i class="fa fa-check"></i><b>5.1.3</b> (Eng.) Grouping and Aggregation</a></li>
<li class="chapter" data-level="5.1.4" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#eng.-transforming-text"><i class="fa fa-check"></i><b>5.1.4</b> (Eng.) Transforming text</a></li>
<li class="chapter" data-level="5.1.5" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#eng.-re-scaling-numerical-values"><i class="fa fa-check"></i><b>5.1.5</b> (Eng.) Re-Scaling Numerical Values</a></li>
<li class="chapter" data-level="5.1.6" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#eng.-discretizations"><i class="fa fa-check"></i><b>5.1.6</b> (Eng.) Discretizations</a></li>
<li class="chapter" data-level="5.1.7" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#eng.-information-content"><i class="fa fa-check"></i><b>5.1.7</b> (Eng.) Information Content</a></li>
<li class="chapter" data-level="5.1.8" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#eng.-reformatting-type-conversion-casting-or-coercion"><i class="fa fa-check"></i><b>5.1.8</b> (Eng.) Reformatting, Type Conversion, Casting or Coercion</a></li>
<li class="chapter" data-level="5.1.9" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#eng.-changing-numerical-values"><i class="fa fa-check"></i><b>5.1.9</b> (Eng.) Changing numerical Values</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#eng.-changing-category-names"><i class="fa fa-check"></i><b>5.2</b> (Eng.) Changing Category Names</a></li>
<li class="chapter" data-level="5.3" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#eng.-imputation"><i class="fa fa-check"></i><b>5.3</b> (Eng.) Imputation</a></li>
<li class="chapter" data-level="5.4" data-path="manipuleren-van-data.html"><a href="manipuleren-van-data.html#onbehandeld"><i class="fa fa-check"></i><b>5.4</b> Onbehandeld</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="de-percetron.html"><a href="de-percetron.html"><i class="fa fa-check"></i><b>6</b> De percetron</a><ul>
<li class="chapter" data-level="6.1" data-path="de-percetron.html"><a href="de-percetron.html#historiek"><i class="fa fa-check"></i><b>6.1</b> Historiek</a></li>
<li class="chapter" data-level="6.2" data-path="de-percetron.html"><a href="de-percetron.html#de-anatomie-van-de-perceptron"><i class="fa fa-check"></i><b>6.2</b> De anatomie van de perceptron</a></li>
<li class="chapter" data-level="6.3" data-path="de-percetron.html"><a href="de-percetron.html#casestudy-onderscheiden-van-setosa"><i class="fa fa-check"></i><b>6.3</b> Casestudy: Onderscheiden van setosa</a></li>
<li class="chapter" data-level="6.4" data-path="de-percetron.html"><a href="de-percetron.html#de-perceptron-klasse"><i class="fa fa-check"></i><b>6.4</b> De perceptron klasse</a></li>
<li class="chapter" data-level="6.5" data-path="de-percetron.html"><a href="de-percetron.html#de-perceptron-functies"><i class="fa fa-check"></i><b>6.5</b> De perceptron functies</a></li>
<li class="chapter" data-level="6.6" data-path="de-percetron.html"><a href="de-percetron.html#het-leeralgoritme-van-de-perceptron"><i class="fa fa-check"></i><b>6.6</b> Het leeralgoritme van de perceptron</a></li>
<li class="chapter" data-level="6.7" data-path="de-percetron.html"><a href="de-percetron.html#trainen-van-de-perceptron"><i class="fa fa-check"></i><b>6.7</b> Trainen van de perceptron</a></li>
<li class="chapter" data-level="6.8" data-path="de-percetron.html"><a href="de-percetron.html#voorspellen-van-de-iris-soort"><i class="fa fa-check"></i><b>6.8</b> Voorspellen van de iris soort</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><a href="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><i class="fa fa-check"></i><b>7</b> Inleiding tot ArtificiÃ«le Neurale Netwerken</a><ul>
<li class="chapter" data-level="7.1" data-path="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><a href="inleiding-tot-artificiÃ«le-neurale-netwerken.html#geschakelde-perceptronen"><i class="fa fa-check"></i><b>7.1</b> Geschakelde perceptronen</a></li>
<li class="chapter" data-level="7.2" data-path="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><a href="inleiding-tot-artificiÃ«le-neurale-netwerken.html#feed-forward-anns-ff-anns"><i class="fa fa-check"></i><b>7.2</b> Feed-forward ANNs (FF-ANNs)</a></li>
<li class="chapter" data-level="7.3" data-path="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><a href="inleiding-tot-artificiÃ«le-neurale-netwerken.html#types-neuronen"><i class="fa fa-check"></i><b>7.3</b> Types neuronen</a></li>
<li class="chapter" data-level="7.4" data-path="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><a href="inleiding-tot-artificiÃ«le-neurale-netwerken.html#backpropagation"><i class="fa fa-check"></i><b>7.4</b> Backpropagation</a></li>
<li class="chapter" data-level="7.5" data-path="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><a href="inleiding-tot-artificiÃ«le-neurale-netwerken.html#de-verliesfunctie-en-kost-functies"><i class="fa fa-check"></i><b>7.5</b> De verliesfunctie en kost-functies</a></li>
<li class="chapter" data-level="7.6" data-path="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><a href="inleiding-tot-artificiÃ«le-neurale-netwerken.html#gradiÃ«nt-afdaling"><i class="fa fa-check"></i><b>7.6</b> GradiÃ«nt afdaling</a></li>
<li class="chapter" data-level="7.7" data-path="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><a href="inleiding-tot-artificiÃ«le-neurale-netwerken.html#stochastische-en-minibatch-gradiÃ«nt-afdaling"><i class="fa fa-check"></i><b>7.7</b> Stochastische en Minibatch gradiÃ«nt afdaling</a></li>
<li class="chapter" data-level="7.8" data-path="inleiding-tot-artificiÃ«le-neurale-netwerken.html"><a href="inleiding-tot-artificiÃ«le-neurale-netwerken.html#regularisatie"><i class="fa fa-check"></i><b>7.8</b> Regularisatie</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html"><i class="fa fa-check"></i><b>8</b> Convolutionele Neurale Netwerken (CNN)</a><ul>
<li class="chapter" data-level="8.1" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#het-onstaan-van-computer-vision"><i class="fa fa-check"></i><b>8.1</b> Het onstaan van Computer Vision</a></li>
<li class="chapter" data-level="8.2" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#waarom-vanilla-sgd-netwerken-ontoereikend-zijn"><i class="fa fa-check"></i><b>8.2</b> Waarom vanilla SGD netwerken ontoereikend zijn</a></li>
<li class="chapter" data-level="8.3" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#de-cnn-filter"><i class="fa fa-check"></i><b>8.3</b> De CNN Filter</a></li>
<li class="chapter" data-level="8.4" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#de-filter-binnen-een-nn"><i class="fa fa-check"></i><b>8.4</b> De filter binnen een NN</a></li>
<li class="chapter" data-level="8.5" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#filter-als-compressor"><i class="fa fa-check"></i><b>8.5</b> Filter als compressor</a></li>
<li class="chapter" data-level="8.6" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#de-stride-niet-opgeven"><i class="fa fa-check"></i><b>8.6</b> De <em>stride</em> niet opgeven</a></li>
<li class="chapter" data-level="8.7" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#de-volledige-filter-laag"><i class="fa fa-check"></i><b>8.7</b> De volledige filter-laag</a></li>
<li class="chapter" data-level="8.8" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#meerdere-filters-per-laag"><i class="fa fa-check"></i><b>8.8</b> Meerdere filters per laag</a></li>
<li class="chapter" data-level="8.9" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#max-pooling"><i class="fa fa-check"></i><b>8.9</b> Max Pooling</a></li>
<li class="chapter" data-level="8.10" data-path="convolutionele-neurale-netwerken-cnn.html"><a href="convolutionele-neurale-netwerken-cnn.html#samenstellen-van-cnns"><i class="fa fa-check"></i><b>8.10</b> Samenstellen van CNNs</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="autoencoders.html"><a href="autoencoders.html"><i class="fa fa-check"></i><b>9</b> Autoencoders</a><ul>
<li class="chapter" data-level="9.1" data-path="autoencoders.html"><a href="autoencoders.html#probleemstelling-rond-dimensionaliteit-en-complexiteit"><i class="fa fa-check"></i><b>9.1</b> Probleemstelling rond Dimensionaliteit en Complexiteit</a></li>
<li class="chapter" data-level="9.2" data-path="autoencoders.html"><a href="autoencoders.html#dimensionaliteit-reduceren"><i class="fa fa-check"></i><b>9.2</b> Dimensionaliteit reduceren</a></li>
<li class="chapter" data-level="9.3" data-path="autoencoders.html"><a href="autoencoders.html#pca-om-dimensionaliteit-te-reduceren"><i class="fa fa-check"></i><b>9.3</b> PCA om dimensionaliteit te reduceren</a></li>
<li class="chapter" data-level="9.4" data-path="autoencoders.html"><a href="autoencoders.html#pca-op-de-mnist-dataset"><i class="fa fa-check"></i><b>9.4</b> PCA op de MNIST dataset</a></li>
<li class="chapter" data-level="9.5" data-path="autoencoders.html"><a href="autoencoders.html#beperkingen-van-pca"><i class="fa fa-check"></i><b>9.5</b> Beperkingen van PCA</a></li>
<li class="chapter" data-level="9.6" data-path="autoencoders.html"><a href="autoencoders.html#de-architectuur-van-de-autoencoder"><i class="fa fa-check"></i><b>9.6</b> De Architectuur van de Autoencoder</a></li>
<li class="chapter" data-level="9.7" data-path="autoencoders.html"><a href="autoencoders.html#autoencoder-op-de-mnist-dataset"><i class="fa fa-check"></i><b>9.7</b> Autoencoder op de MNIST dataset</a></li>
<li class="chapter" data-level="9.8" data-path="autoencoders.html"><a href="autoencoders.html#autoencoder-met-cnn"><i class="fa fa-check"></i><b>9.8</b> Autoencoder met CNN</a></li>
<li class="chapter" data-level="9.9" data-path="autoencoders.html"><a href="autoencoders.html#autoencoder-als-ruis-verwijderaar"><i class="fa fa-check"></i><b>9.9</b> Autoencoder als ruis-verwijderaar</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="trainen-en-testen.html"><a href="trainen-en-testen.html"><i class="fa fa-check"></i><b>10</b> Trainen en testen</a><ul>
<li class="chapter" data-level="10.1" data-path="trainen-en-testen.html"><a href="trainen-en-testen.html#leren-leven-met-de-onzekerheid"><i class="fa fa-check"></i><b>10.1</b> Leren leven met de onzekerheid</a></li>
<li class="chapter" data-level="10.2" data-path="trainen-en-testen.html"><a href="trainen-en-testen.html#meten-van-de-prestatie-van-een-model"><i class="fa fa-check"></i><b>10.2</b> Meten van de prestatie van een model</a></li>
<li class="chapter" data-level="10.3" data-path="trainen-en-testen.html"><a href="trainen-en-testen.html#training--validatie--en-test-set"><i class="fa fa-check"></i><b>10.3</b> Training-, validatie- en test-set</a></li>
<li class="chapter" data-level="10.4" data-path="trainen-en-testen.html"><a href="trainen-en-testen.html#cross-validatie"><i class="fa fa-check"></i><b>10.4</b> Cross-validatie</a></li>
<li class="chapter" data-level="10.5" data-path="trainen-en-testen.html"><a href="trainen-en-testen.html#werkstroom-deep-learning"><i class="fa fa-check"></i><b>10.5</b> Werkstroom deep learning</a></li>
<li class="chapter" data-level="10.6" data-path="trainen-en-testen.html"><a href="trainen-en-testen.html#data-lekkage"><i class="fa fa-check"></i><b>10.6</b> Data lekkage</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="sequentie-analyse.html"><a href="sequentie-analyse.html"><i class="fa fa-check"></i><b>11</b> Sequentie Analyse</a><ul>
<li class="chapter" data-level="11.1" data-path="sequentie-analyse.html"><a href="sequentie-analyse.html#inleiding-tot-sequentie-analyse"><i class="fa fa-check"></i><b>11.1</b> Inleiding tot sequentie analyse</a></li>
<li class="chapter" data-level="11.2" data-path="sequentie-analyse.html"><a href="sequentie-analyse.html#sequence-to-sequence"><i class="fa fa-check"></i><b>11.2</b> Sequence-To-Sequence</a></li>
<li class="chapter" data-level="11.3" data-path="sequentie-analyse.html"><a href="sequentie-analyse.html#recurrente-nn"><i class="fa fa-check"></i><b>11.3</b> Recurrente NN</a></li>
<li class="chapter" data-level="11.4" data-path="sequentie-analyse.html"><a href="sequentie-analyse.html#verdwijnende-gradiÃ«nten"><i class="fa fa-check"></i><b>11.4</b> Verdwijnende gradiÃ«nten</a></li>
<li class="chapter" data-level="11.5" data-path="sequentie-analyse.html"><a href="sequentie-analyse.html#long-short-term-memory-lstm"><i class="fa fa-check"></i><b>11.5</b> Long short-term memory (LSTM)</a></li>
<li class="chapter" data-level="11.6" data-path="sequentie-analyse.html"><a href="sequentie-analyse.html#sentiment-analyse"><i class="fa fa-check"></i><b>11.6</b> Sentiment analyse</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html"><i class="fa fa-check"></i><b>12</b> Neurale Netwerken met Extern Geheugen</a><ul>
<li class="chapter" data-level="12.1" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#inleiding-nn-met-extern-geheugen"><i class="fa fa-check"></i><b>12.1</b> Inleiding NN met extern geheugen</a></li>
<li class="chapter" data-level="12.2" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#neurale-turing-machines"><i class="fa fa-check"></i><b>12.2</b> Neurale Turing Machines</a></li>
<li class="chapter" data-level="12.3" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#lezen-uit-en-schrijven-naar-een-ntm-geheugen"><i class="fa fa-check"></i><b>12.3</b> Lezen uit en schrijven naar een NTM geheugen</a></li>
<li class="chapter" data-level="12.4" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#adressering-van-ntm-geheugens"><i class="fa fa-check"></i><b>12.4</b> Adressering van NTM geheugens</a></li>
<li class="chapter" data-level="12.5" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#inhoud-gebaseerde-adressering"><i class="fa fa-check"></i><b>12.5</b> Inhoud-gebaseerde adressering</a></li>
<li class="chapter" data-level="12.6" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#locatie-gebaseerde-adressering"><i class="fa fa-check"></i><b>12.6</b> Locatie-gebaseerde adressering</a></li>
<li class="chapter" data-level="12.7" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#adresseringsmechanisme"><i class="fa fa-check"></i><b>12.7</b> Adresseringsmechanisme</a></li>
<li class="chapter" data-level="12.8" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#de-nadelen-van-ntms"><i class="fa fa-check"></i><b>12.8</b> De nadelen van NTMs</a></li>
<li class="chapter" data-level="12.9" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#de-differentiÃ«le-neurale-computer"><i class="fa fa-check"></i><b>12.9</b> De differentiÃ«le neurale computer</a></li>
<li class="chapter" data-level="12.10" data-path="neurale-netwerken-met-extern-geheugen.html"><a href="neurale-netwerken-met-extern-geheugen.html#implementatie-dnc"><i class="fa fa-check"></i><b>12.10</b> Implementatie DNC</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html"><i class="fa fa-check"></i><b>13</b> Deep Reinforcement Learning</a><ul>
<li class="chapter" data-level="13.1" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#inleiding-deep-rl"><i class="fa fa-check"></i><b>13.1</b> Inleiding Deep RL</a></li>
<li class="chapter" data-level="13.2" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#voorbeelden-van-deep-reinforcement-learning"><i class="fa fa-check"></i><b>13.2</b> Voorbeelden van deep reinforcement learning</a><ul>
<li class="chapter" data-level="13.2.1" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#introductie-deepmind-team"><i class="fa fa-check"></i><b>13.2.1</b> Introductie DeepMind Team</a></li>
<li class="chapter" data-level="13.2.2" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#deepminds-deep-q-learning"><i class="fa fa-check"></i><b>13.2.2</b> DeepMindâ€™s Deep-Q learning</a></li>
<li class="chapter" data-level="13.2.3" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#robot-tasks"><i class="fa fa-check"></i><b>13.2.3</b> Robot tasks</a></li>
<li class="chapter" data-level="13.2.4" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#atlas"><i class="fa fa-check"></i><b>13.2.4</b> Atlas</a></li>
<li class="chapter" data-level="13.2.5" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#cart-pole"><i class="fa fa-check"></i><b>13.2.5</b> Cart-Pole</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#markov-beslissingsproces"><i class="fa fa-check"></i><b>13.3</b> Markov beslissingsproces</a></li>
<li class="chapter" data-level="13.4" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#deep-reinforcement-learning-1"><i class="fa fa-check"></i><b>13.4</b> Deep Reinforcement Learning</a></li>
<li class="chapter" data-level="13.5" data-path="deep-reinforcement-learning.html"><a href="deep-reinforcement-learning.html#varianten-van-deep-rl"><i class="fa fa-check"></i><b>13.5</b> Varianten van (Deep) RL</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="rapporteren.html"><a href="rapporteren.html"><i class="fa fa-check"></i><b>14</b> Rapporteren</a><ul>
<li class="chapter" data-level="14.1" data-path="rapporteren.html"><a href="rapporteren.html#vormen-van-schriftelijke-communicatie"><i class="fa fa-check"></i><b>14.1</b> Vormen van schriftelijke communicatie</a></li>
<li class="chapter" data-level="14.2" data-path="rapporteren.html"><a href="rapporteren.html#de-vraagstelling"><i class="fa fa-check"></i><b>14.2</b> De vraagstelling</a></li>
<li class="chapter" data-level="14.3" data-path="rapporteren.html"><a href="rapporteren.html#de-probleemstelling"><i class="fa fa-check"></i><b>14.3</b> De probleemstelling</a></li>
<li class="chapter" data-level="14.4" data-path="rapporteren.html"><a href="rapporteren.html#uitvoering-ai-project"><i class="fa fa-check"></i><b>14.4</b> Uitvoering AI project</a><ul>
<li class="chapter" data-level="14.4.1" data-path="rapporteren.html"><a href="rapporteren.html#reproduceerbare-willekeur"><i class="fa fa-check"></i><b>14.4.1</b> Reproduceerbare willekeur</a></li>
<li class="chapter" data-level="14.4.2" data-path="rapporteren.html"><a href="rapporteren.html#tools"><i class="fa fa-check"></i><b>14.4.2</b> Tools</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="rapporteren.html"><a href="rapporteren.html#de-inleiding-van-een-rapport"><i class="fa fa-check"></i><b>14.5</b> De inleiding van een rapport</a></li>
<li class="chapter" data-level="14.6" data-path="rapporteren.html"><a href="rapporteren.html#methodiek"><i class="fa fa-check"></i><b>14.6</b> Methodiek</a><ul>
<li class="chapter" data-level="14.6.1" data-path="rapporteren.html"><a href="rapporteren.html#data-beschikbaar-maken"><i class="fa fa-check"></i><b>14.6.1</b> Data beschikbaar maken</a></li>
<li class="chapter" data-level="14.6.2" data-path="rapporteren.html"><a href="rapporteren.html#beschikbaar-maken-van-databanken"><i class="fa fa-check"></i><b>14.6.2</b> Beschikbaar maken van databanken</a></li>
<li class="chapter" data-level="14.6.3" data-path="rapporteren.html"><a href="rapporteren.html#procesbeschrijving"><i class="fa fa-check"></i><b>14.6.3</b> Procesbeschrijving</a></li>
<li class="chapter" data-level="14.6.4" data-path="rapporteren.html"><a href="rapporteren.html#voorbeeld-uit-wang-et-al."><i class="fa fa-check"></i><b>14.6.4</b> Voorbeeld uit Wang et al.</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="rapporteren.html"><a href="rapporteren.html#resultaten"><i class="fa fa-check"></i><b>14.7</b> Resultaten</a><ul>
<li class="chapter" data-level="14.7.1" data-path="rapporteren.html"><a href="rapporteren.html#beduidende-cijfers"><i class="fa fa-check"></i><b>14.7.1</b> Beduidende cijfers</a></li>
<li class="chapter" data-level="14.7.2" data-path="rapporteren.html"><a href="rapporteren.html#onzekere-cijfers"><i class="fa fa-check"></i><b>14.7.2</b> Onzekere cijfers</a></li>
<li class="chapter" data-level="14.7.3" data-path="rapporteren.html"><a href="rapporteren.html#visuele-cijfers"><i class="fa fa-check"></i><b>14.7.3</b> Visuele cijfers</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="rapporteren.html"><a href="rapporteren.html#discussie-en-conclusie"><i class="fa fa-check"></i><b>14.8</b> Discussie en Conclusie</a></li>
<li class="chapter" data-level="14.9" data-path="rapporteren.html"><a href="rapporteren.html#afsluiten-met-de-samenvatting"><i class="fa fa-check"></i><b>14.9</b> Afsluiten met de samenvatting</a></li>
<li class="chapter" data-level="14.10" data-path="rapporteren.html"><a href="rapporteren.html#verwijzen-naar-extern-werk"><i class="fa fa-check"></i><b>14.10</b> Verwijzen naar extern werk</a><ul>
<li class="chapter" data-level="14.10.1" data-path="rapporteren.html"><a href="rapporteren.html#citeren"><i class="fa fa-check"></i><b>14.10.1</b> Citeren</a></li>
<li class="chapter" data-level="14.10.2" data-path="rapporteren.html"><a href="rapporteren.html#licenties-en-toestemming"><i class="fa fa-check"></i><b>14.10.2</b> Licenties en toestemming</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ethisch-ml.html"><a href="ethisch-ml.html"><i class="fa fa-check"></i><b>15</b> Ethisch ML</a><ul>
<li class="chapter" data-level="15.1" data-path="ethisch-ml.html"><a href="ethisch-ml.html#inleiding-tot-de-ml-ethiek"><i class="fa fa-check"></i><b>15.1</b> Inleiding tot de ML-ethiek</a></li>
<li class="chapter" data-level="15.2" data-path="ethisch-ml.html"><a href="ethisch-ml.html#hoe-het-niet-moet"><i class="fa fa-check"></i><b>15.2</b> Hoe het niet moet</a><ul>
<li class="chapter" data-level="15.2.1" data-path="ethisch-ml.html"><a href="ethisch-ml.html#gender-ongelijkheid"><i class="fa fa-check"></i><b>15.2.1</b> Gender-ongelijkheid</a></li>
<li class="chapter" data-level="15.2.2" data-path="ethisch-ml.html"><a href="ethisch-ml.html#onmenselijk"><i class="fa fa-check"></i><b>15.2.2</b> Onmenselijk</a></li>
<li class="chapter" data-level="15.2.3" data-path="ethisch-ml.html"><a href="ethisch-ml.html#vals-gevoel-van-controle"><i class="fa fa-check"></i><b>15.2.3</b> Vals gevoel van controle</a></li>
<li class="chapter" data-level="15.2.4" data-path="ethisch-ml.html"><a href="ethisch-ml.html#gamification"><i class="fa fa-check"></i><b>15.2.4</b> Gamification</a></li>
<li class="chapter" data-level="15.2.5" data-path="ethisch-ml.html"><a href="ethisch-ml.html#ongewilde-advertenties"><i class="fa fa-check"></i><b>15.2.5</b> Ongewilde advertenties</a></li>
<li class="chapter" data-level="15.2.6" data-path="ethisch-ml.html"><a href="ethisch-ml.html#huidskleur"><i class="fa fa-check"></i><b>15.2.6</b> Huidskleur</a></li>
<li class="chapter" data-level="15.2.7" data-path="ethisch-ml.html"><a href="ethisch-ml.html#polarisatie"><i class="fa fa-check"></i><b>15.2.7</b> Polarisatie</a></li>
<li class="chapter" data-level="15.2.8" data-path="ethisch-ml.html"><a href="ethisch-ml.html#gezondheid"><i class="fa fa-check"></i><b>15.2.8</b> Gezondheid</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="ethisch-ml.html"><a href="ethisch-ml.html#de-oorzaken-van-onethisch-ai-producten"><i class="fa fa-check"></i><b>15.3</b> De oorzaken van onethisch AI-producten</a></li>
<li class="chapter" data-level="15.4" data-path="ethisch-ml.html"><a href="ethisch-ml.html#representativiteit"><i class="fa fa-check"></i><b>15.4</b> Representativiteit</a></li>
<li class="chapter" data-level="15.5" data-path="ethisch-ml.html"><a href="ethisch-ml.html#randvoorwaarden"><i class="fa fa-check"></i><b>15.5</b> Randvoorwaarden</a></li>
<li class="chapter" data-level="15.6" data-path="ethisch-ml.html"><a href="ethisch-ml.html#privacy-en-ethiek"><i class="fa fa-check"></i><b>15.6</b> Privacy en ethiek</a></li>
<li class="chapter" data-level="15.7" data-path="ethisch-ml.html"><a href="ethisch-ml.html#privacy"><i class="fa fa-check"></i><b>15.7</b> Privacy</a></li>
<li class="chapter" data-level="15.8" data-path="ethisch-ml.html"><a href="ethisch-ml.html#de-drie-wetten-van-asimov"><i class="fa fa-check"></i><b>15.8</b> De drie wetten van Asimov</a></li>
<li class="chapter" data-level="15.9" data-path="ethisch-ml.html"><a href="ethisch-ml.html#ethiek"><i class="fa fa-check"></i><b>15.9</b> Ethiek</a></li>
<li class="chapter" data-level="15.10" data-path="ethisch-ml.html"><a href="ethisch-ml.html#proces-om-etisch-te-blijven"><i class="fa fa-check"></i><b>15.10</b> Proces om etisch te blijven</a></li>
<li class="chapter" data-level="15.11" data-path="ethisch-ml.html"><a href="ethisch-ml.html#regels-rond-ethiek"><i class="fa fa-check"></i><b>15.11</b> Regels rond ethiek</a></li>
<li class="chapter" data-level="15.12" data-path="ethisch-ml.html"><a href="ethisch-ml.html#eed"><i class="fa fa-check"></i><b>15.12</b> Eed</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="de-logaritme.html"><a href="de-logaritme.html"><i class="fa fa-check"></i><b>A</b> De Logaritme</a></li>
<li class="chapter" data-level="B" data-path="normaliseren-versus-standaardiseren.html"><a href="normaliseren-versus-standaardiseren.html"><i class="fa fa-check"></i><b>B</b> Normaliseren versus Standaardiseren</a></li>
<li class="chapter" data-level="C" data-path="inwendig-product-matrix-vermenigvuldiging-vectoren-en-tensoren.html"><a href="inwendig-product-matrix-vermenigvuldiging-vectoren-en-tensoren.html"><i class="fa fa-check"></i><b>C</b> Inwendig product, matrix-vermenigvuldiging, vectoren en tensoren</a></li>
<li class="chapter" data-level="D" data-path="computations-using-gpu.html"><a href="computations-using-gpu.html"><i class="fa fa-check"></i><b>D</b> Computations using GPU</a></li>
<li class="chapter" data-level="E" data-path="installation.html"><a href="installation.html"><i class="fa fa-check"></i><b>E</b> Installation</a><ul>
<li class="chapter" data-level="E.1" data-path="installation.html"><a href="installation.html#installing-cuda-optional"><i class="fa fa-check"></i><b>E.1</b> Installing CUDA (optional)</a></li>
<li class="chapter" data-level="E.2" data-path="installation.html"><a href="installation.html#the-r-language"><i class="fa fa-check"></i><b>E.2</b> The R language</a></li>
<li class="chapter" data-level="E.3" data-path="installation.html"><a href="installation.html#python"><i class="fa fa-check"></i><b>E.3</b> Python</a></li>
<li class="chapter" data-level="E.4" data-path="installation.html"><a href="installation.html#rstudio"><i class="fa fa-check"></i><b>E.4</b> RStudio</a></li>
<li class="chapter" data-level="E.5" data-path="installation.html"><a href="installation.html#installing-tensorflow"><i class="fa fa-check"></i><b>E.5</b> Installing Tensorflow</a></li>
<li class="chapter" data-level="E.6" data-path="installation.html"><a href="installation.html#installation-steps-that-worked-for-the-author"><i class="fa fa-check"></i><b>E.6</b> Installation steps that worked for the author</a></li>
<li class="chapter" data-level="E.7" data-path="installation.html"><a href="installation.html#waar-vind-ik-hulp"><i class="fa fa-check"></i><b>E.7</b> Waar vind ik hulp</a></li>
<li class="chapter" data-level="E.8" data-path="installation.html"><a href="installation.html#waar-kan-ik-leeralgoritmen-terugvinden"><i class="fa fa-check"></i><b>E.8</b> Waar kan ik leeralgoritmen terugvinden</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>F</b> Git</a></li>
<li class="chapter" data-level="G" data-path="antwoorden.html"><a href="antwoorden.html"><i class="fa fa-check"></i><b>G</b> Antwoorden</a><ul>
<li class="chapter" data-level="G.1" data-path="antwoorden.html"><a href="antwoorden.html#hoofdstuk-4"><i class="fa fa-check"></i><b>G.1</b> Hoofdstuk 4</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bronvermelding.html"><a href="bronvermelding.html"><i class="fa fa-check"></i>Bronvermelding</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="autoencoders" class="section level1">
<h1><span class="header-section-number">Hoofdstuk 9</span> Autoencoders</h1>
<div id="probleemstelling-rond-dimensionaliteit-en-complexiteit" class="section level2">
<h2><span class="header-section-number">9.1</span> Probleemstelling rond Dimensionaliteit en Complexiteit</h2>
<p>Complexe problemen dienen opgelost te worden met complexe NN. Maar complexe NN vereisen meer data (eng: <em>are more data hungry</em>). Indien complexe modellen onvoldoende data te verwerken krijgen is er een grotere kans op overfitting.</p>
<p>Een mogelijke oplossing voor bovenstaand probleem is het reduceren van het aantal dimensies van de invoer-data. We nemen alweer de MNIST dataset als voorbeeld. Deze invoer data bestaat uit 784 pixels en in platte tabel vorm hebben we voor elke instantie 784 waarden verdeeld over evenveel kolommen. Wat als we zouden proberen het aantal variabelen terug te brengen tot een kleiner aantal? Je zou kunnen redeneren: waarom niet de beelden van de cijfers te comprimeren van 28 Ã— 28 pixels naar bijvoorbeeld 5 Ã— 5 pixels. Deze benadering is mogelijk maar niet erg efficiÃ«nt, omdat niet elke pixels van de afbeelding evenveel bijdraagt tot de classificatie. Er is een betere benadering, noem het een â€˜slim compressie-algoritmeâ€™, die we de <em>autoencoder</em> noemen.</p>
</div>
<div id="dimensionaliteit-reduceren" class="section level2">
<h2><span class="header-section-number">9.2</span> Dimensionaliteit reduceren</h2>
<p>De doelstelling van een autoencoder is om eenvoudigere modellen te maken in situaties waarbij:</p>
<ol style="list-style-type: decimal">
<li>er slechts een beperkte hoeveelheid data beschikbaar is</li>
<li>de data nogal complex is (veel variabelen)</li>
<li>de onderliggende patronen vermoedelijk relatief eenvoudig zijn</li>
</ol>
<p>De autoencoder is een functie die dus zal trachten om de dimensionaliteit van de invoer data te reduceren (eng: <em>dimensionality reduction</em>) hetgeen er dus op neer komt om het aantal variabelen te verminderen zonder al te veel informatie te verliezen.</p>

<div class="definition">
<p><span id="def:slimme-compressie" class="definition"><strong>Stelling 9.1  (Eigenschappen van een goede autoencoder)  </strong></span></p>
<ul>
<li><strong>Data-type specifiek</strong>: Een autoencoder werkt niet zoals een beeld-compressie algoritme of als een ZIP-functie op eender welk type data, in plaats daarvan werkt de autoencoder op basis van de inhoud. Dat betekent dat een autoencoder getraind op autoâ€™s niet geschikt is voor het comprimeren van afbeeldingen van huiskatten.</li>
<li><strong>Niet perfect</strong>: (eng: <em>lossy</em>) Na een decompressie bekoemt nooit nooit exact de oorpronkelijke data. Met autoencoder verlies je altijd data.</li>
<li><strong>Zelflerend</strong>: (eng: <em>self-supervised</em>) een autoencoder heeft geen input nodig van buitenaf buiten een beperkt aantal hyperparameters
</div></li>
</ul>
</div>
<div id="pca-om-dimensionaliteit-te-reduceren" class="section level2">
<h2><span class="header-section-number">9.3</span> PCA om dimensionaliteit te reduceren</h2>
<p>PCA is familie aan onbegeleide leeralgoritmen die bekend staat om de dimensionaliteit van de data te kunnen verlagen, i.e.Â door het aantal variabelen te verminderen zonder al te veel van de onderliggende patronen (of â€˜informatieâ€™) te verliezen. We genereren nog eens een puntenwolk waarbij twee hypothetische variabelen met een sterke correlatie (<span class="math inline">\(\rho = 0,7\)</span>) worden uitgebeeld:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="autoencoders.html#cb78-1"></a><span class="kw">library</span>(MASS)</span>
<span id="cb78-2"><a href="autoencoders.html#cb78-2"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb78-3"><a href="autoencoders.html#cb78-3"></a></span>
<span id="cb78-4"><a href="autoencoders.html#cb78-4"></a>copula &lt;-<span class="st"> </span><span class="cf">function</span>(n, rho, mu1, mu2, sd1, sd2, names){</span>
<span id="cb78-5"><a href="autoencoders.html#cb78-5"></a>  mu &lt;-<span class="st"> </span><span class="kw">c</span>(mu1,mu2)</span>
<span id="cb78-6"><a href="autoencoders.html#cb78-6"></a>  sigma &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(sd1 <span class="op">^</span><span class="st"> </span><span class="dv">2</span>, sd1 <span class="op">*</span><span class="st"> </span>sd2 <span class="op">*</span><span class="st"> </span>rho, sd1 <span class="op">*</span><span class="st"> </span>sd2 <span class="op">*</span><span class="st"> </span>rho, sd2 <span class="op">^</span><span class="st"> </span><span class="dv">2</span>),<span class="dv">2</span>)</span>
<span id="cb78-7"><a href="autoencoders.html#cb78-7"></a>  <span class="kw">mvrnorm</span>(n, mu, sigma) <span class="op">%&gt;%</span><span class="st"> </span>as.data.table <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">set_names</span>(names)</span>
<span id="cb78-8"><a href="autoencoders.html#cb78-8"></a>}</span>
<span id="cb78-9"><a href="autoencoders.html#cb78-9"></a></span>
<span id="cb78-10"><a href="autoencoders.html#cb78-10"></a>dat &lt;-<span class="st"> </span><span class="kw">copula</span>(<span class="dv">100</span>, <span class="fl">.7</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">.3</span>, <span class="fl">.5</span>, <span class="kw">c</span>(<span class="st">&quot;X1&quot;</span>, <span class="st">&quot;X2&quot;</span>))</span>
<span id="cb78-11"><a href="autoencoders.html#cb78-11"></a>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot</span>(<span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">asp =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="dv">1</span>)</span>
<span id="cb78-12"><a href="autoencoders.html#cb78-12"></a><span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">v =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/pca-demo-copula-1.png" width="672" /></p>
<p>We voeren nu de PCA uit en kijken naar het resultaat:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="autoencoders.html#cb79-1"></a>dat_pca &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span>prcomp</span>
<span id="cb79-2"><a href="autoencoders.html#cb79-2"></a>rot &lt;-<span class="st"> </span>dat_pca<span class="op">$</span>rotation</span>
<span id="cb79-3"><a href="autoencoders.html#cb79-3"></a></span>
<span id="cb79-4"><a href="autoencoders.html#cb79-4"></a>dat_pca<span class="op">$</span>x <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot</span>(<span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">asp =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="dv">1</span>)</span>
<span id="cb79-5"><a href="autoencoders.html#cb79-5"></a><span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">v =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/pca-demo-run-1.png" width="672" /></p>
<p>Wat is er gebeurd? Eerst zoekt het PCA-algoritme eigen-vector die in de richting wijst van de sterkste variantie. PCA gaat er namelijk van uit dat de hoeveelheid variantie een goede maat is voor de hoeveelheid informatie. Deze eerste vector worden de eerste <em>principale component</em>. In ons voorbeeld wordt deze opgebouwd als -0.434 Â· X1 + -0.901 Â· X2.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="autoencoders.html#cb80-1"></a>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot</span>(<span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">asp =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="dv">1</span>)</span>
<span id="cb80-2"><a href="autoencoders.html#cb80-2"></a><span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">v =</span> <span class="dv">0</span>)</span>
<span id="cb80-3"><a href="autoencoders.html#cb80-3"></a><span class="kw">arrows</span>(<span class="dv">0</span>, <span class="dv">0</span>, rot[<span class="dv">1</span>, <span class="dv">1</span>], rot[<span class="dv">2</span>, <span class="dv">1</span>], <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">col =</span> <span class="dv">4</span>)</span>
<span id="cb80-4"><a href="autoencoders.html#cb80-4"></a><span class="kw">text</span>(rot[<span class="dv">1</span>, <span class="dv">1</span>], rot[<span class="dv">2</span>, <span class="dv">1</span>], <span class="st">&quot;PC1&quot;</span>, <span class="dt">col =</span> <span class="dv">4</span>, <span class="dt">adj =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">font =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>Voor de tweede component zoekt het algoritme een richting loodrecht op de eerste waarin zich de meeste variantie bevindt.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="autoencoders.html#cb81-1"></a>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot</span>(<span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">asp =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="dv">1</span>)</span>
<span id="cb81-2"><a href="autoencoders.html#cb81-2"></a><span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">v =</span> <span class="dv">0</span>)</span>
<span id="cb81-3"><a href="autoencoders.html#cb81-3"></a><span class="kw">arrows</span>(<span class="dv">0</span>, <span class="dv">0</span>, rot[<span class="dv">1</span>, <span class="dv">1</span>], rot[<span class="dv">2</span>, <span class="dv">1</span>], <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="dv">4</span>)</span>
<span id="cb81-4"><a href="autoencoders.html#cb81-4"></a><span class="kw">arrows</span>(<span class="dv">0</span>, <span class="dv">0</span>, rot[<span class="dv">1</span>, <span class="dv">2</span>], rot[<span class="dv">2</span>, <span class="dv">2</span>], <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">col =</span> <span class="dv">4</span>)</span>
<span id="cb81-5"><a href="autoencoders.html#cb81-5"></a></span>
<span id="cb81-6"><a href="autoencoders.html#cb81-6"></a><span class="kw">text</span>(rot[<span class="dv">1</span>, <span class="dv">1</span>], rot[<span class="dv">2</span>, <span class="dv">1</span>], <span class="st">&quot;PC1&quot;</span>, <span class="dt">col =</span> <span class="dv">4</span>, <span class="dt">adj =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">font =</span> <span class="dv">2</span>)</span>
<span id="cb81-7"><a href="autoencoders.html#cb81-7"></a><span class="kw">text</span>(rot[<span class="dv">1</span>, <span class="dv">2</span>], rot[<span class="dv">2</span>, <span class="dv">2</span>], <span class="st">&quot;PC2&quot;</span>, <span class="dt">col =</span> <span class="dv">4</span>, <span class="dt">adj =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">font =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>We zijn vertrokken van twee variabelen, dus is er hier maar Ã©Ã©n andere richting mogelijk. In realistische situaties met meer variabelen, zijn er evenveel loodrechte richtingen mogelijk, hoewel dit in een meerdimensionale ruimte moeilijk voor te stellen is, natuurlijk.</p>
<p>De gecumuleerde hoeveelheid variantie voor deze twee principale componenten ziet er als volgt uit:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="autoencoders.html#cb82-1"></a>dat_pca <span class="op">%&gt;%</span><span class="st"> </span>summary <span class="op">%$%</span><span class="st"> </span>importance <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">extract</span>(<span class="dv">3</span>, ) <span class="op">%&gt;%</span></span>
<span id="cb82-2"><a href="autoencoders.html#cb82-2"></a><span class="st">  </span><span class="kw">barplot</span>(<span class="dt">col =</span> <span class="dv">1</span>, <span class="dt">ylab =</span> <span class="st">&quot;Geacummuleerde variantie verklaard&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<p>De eerste component draagt in zich reeds meer dan 90% van de totale variantie. Stel nu dat dit voldoende is en dat een verlies van zoâ€™n 9% van de informatie aanvaardbaar is. In dat geval kan men beslissen om de eerste component te gebruiken als een gecomprimeerde voorstelling van de oorspronkelijke dataset. Het komt erop naar dat we de â€˜geroteerdeâ€™ versie van de dataset â€˜projecterenâ€™ op de eerste component:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="autoencoders.html#cb83-1"></a>dat_pca<span class="op">$</span>x[, <span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">nrow</span>(dat_pca<span class="op">$</span>x))) <span class="op">%&gt;%</span></span>
<span id="cb83-2"><a href="autoencoders.html#cb83-2"></a><span class="st">  </span><span class="kw">plot</span>(<span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">asp =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="dv">1</span>, <span class="dt">yaxt =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;PC1&quot;</span>)</span>
<span id="cb83-3"><a href="autoencoders.html#cb83-3"></a><span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<p>Merk op dat we met 50% van de data 90% van de informatie behouden. Naarmate dat er meerdere variabelen zijn, zal de compressiefactor nog veel hoger zijn. Laten we PCA eens uitproberen op de MNIST dataset.</p>
</div>
<div id="pca-op-de-mnist-dataset" class="section level2">
<h2><span class="header-section-number">9.4</span> PCA op de MNIST dataset</h2>
<p>Nu dat we het principe van PCA beter begrijpen, kunnen we het proberen toepassen op de MNIST dataset. We beginnen met het definiÃ«ren van een aantal helper-functies.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="autoencoders.html#cb84-1"></a>rotate &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">t</span>(<span class="kw">apply</span>(x, <span class="dv">2</span>, rev))</span>
<span id="cb84-2"><a href="autoencoders.html#cb84-2"></a></span>
<span id="cb84-3"><a href="autoencoders.html#cb84-3"></a>normalize &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</span>
<span id="cb84-4"><a href="autoencoders.html#cb84-4"></a>  x_min &lt;-<span class="st"> </span><span class="kw">min</span>(x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</span>
<span id="cb84-5"><a href="autoencoders.html#cb84-5"></a>  x_max &lt;-<span class="st"> </span><span class="kw">max</span>(x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</span>
<span id="cb84-6"><a href="autoencoders.html#cb84-6"></a>  </span>
<span id="cb84-7"><a href="autoencoders.html#cb84-7"></a>  (x <span class="op">-</span><span class="st"> </span>x_min) <span class="op">/</span><span class="st"> </span>(x_max <span class="op">-</span><span class="st"> </span>x_min)</span>
<span id="cb84-8"><a href="autoencoders.html#cb84-8"></a>}</span>
<span id="cb84-9"><a href="autoencoders.html#cb84-9"></a></span>
<span id="cb84-10"><a href="autoencoders.html#cb84-10"></a>plot_digit &lt;-<span class="st"> </span><span class="cf">function</span>(digit, <span class="dt">title =</span> <span class="st">&quot;&quot;</span>){</span>
<span id="cb84-11"><a href="autoencoders.html#cb84-11"></a>  <span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>))</span>
<span id="cb84-12"><a href="autoencoders.html#cb84-12"></a>  </span>
<span id="cb84-13"><a href="autoencoders.html#cb84-13"></a>  digit <span class="op">%&gt;%</span></span>
<span id="cb84-14"><a href="autoencoders.html#cb84-14"></a><span class="st">    </span>unlist <span class="op">%&gt;%</span></span>
<span id="cb84-15"><a href="autoencoders.html#cb84-15"></a><span class="st">    </span>normalize <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb84-16"><a href="autoencoders.html#cb84-16"></a><span class="st">    </span><span class="kw">matrix</span>(<span class="dt">ncol =</span> <span class="dv">28</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb84-17"><a href="autoencoders.html#cb84-17"></a><span class="st">    </span>rotate <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb84-18"><a href="autoencoders.html#cb84-18"></a><span class="st">    </span><span class="kw">image</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">28</span>, ., <span class="dt">asp =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="kw">gray.colors</span>(<span class="dv">256</span>),</span>
<span id="cb84-19"><a href="autoencoders.html#cb84-19"></a>      <span class="dt">axes =</span> <span class="ot">FALSE</span>)</span>
<span id="cb84-20"><a href="autoencoders.html#cb84-20"></a>  </span>
<span id="cb84-21"><a href="autoencoders.html#cb84-21"></a>  <span class="kw">text</span>(<span class="dv">1</span>, <span class="dv">26</span>, title, <span class="dt">adj =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">col =</span> <span class="st">&quot;white&quot;</span>)</span>
<span id="cb84-22"><a href="autoencoders.html#cb84-22"></a>}</span></code></pre></div>
<p>De <code>rotate</code> functie dient om de matrix een kwartslag te draaien zodat de <code>image</code> functie de afbeelding correct weergeeft. <code>normalize</code> dient om te normaliseren. Voor het verschil tussen normalisatie en standaardisatie verwijs ik naar de <a href="normaliseren-versus-standaardiseren.html#normaliseren-versus-standaardiseren">Appendix</a>. Tenslotte, de <code>plot_digit</code> functie zal de set van grijswaarden als afbeelding weergeven.</p>
<p>In de volgende stap lezen we 100 eerste afbeeldingen uit de MNIST dataset in, zoals die vrijgegeven werd op de <a href="https://pjreddie.com/">blog van Joseph Chet Redmon</a>.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="autoencoders.html#cb85-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb85-2"><a href="autoencoders.html#cb85-2"></a></span>
<span id="cb85-3"><a href="autoencoders.html#cb85-3"></a>mnist &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;dat/mnist_train.csv&quot;</span>)</span>
<span id="cb85-4"><a href="autoencoders.html#cb85-4"></a>mnist &lt;-<span class="st"> </span>mnist[, <span class="dv">2</span><span class="op">:</span><span class="dv">785</span>]</span></code></pre></div>
<p>Net als bij het PCA voorbeeld op de puntenwolk, gaan we nu de PCA uitvoeren en een projectie maken van de <code>k</code> eerste (i.e.Â meest informatieve) principale componenten (<span class="math inline">\(k:{1, 5, 10, 25, 50}\)</span>):</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="autoencoders.html#cb86-1"></a>predict_pca &lt;-<span class="st"> </span><span class="cf">function</span>(x, n) {</span>
<span id="cb86-2"><a href="autoencoders.html#cb86-2"></a>  x<span class="op">$</span>x[, <span class="dv">1</span><span class="op">:</span>n] <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(x<span class="op">$</span>rotation[, <span class="dv">1</span><span class="op">:</span>n]) <span class="op">%&gt;%</span></span>
<span id="cb86-3"><a href="autoencoders.html#cb86-3"></a><span class="st">    </span><span class="kw">scale</span>(<span class="dt">center =</span> <span class="op">-</span>x<span class="op">$</span>center, <span class="dt">scale =</span> <span class="ot">FALSE</span>)</span>
<span id="cb86-4"><a href="autoencoders.html#cb86-4"></a>}</span>
<span id="cb86-5"><a href="autoencoders.html#cb86-5"></a></span>
<span id="cb86-6"><a href="autoencoders.html#cb86-6"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb86-7"><a href="autoencoders.html#cb86-7"></a></span>
<span id="cb86-8"><a href="autoencoders.html#cb86-8"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>) {</span>
<span id="cb86-9"><a href="autoencoders.html#cb86-9"></a>  mnist[i, ] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot_digit</span>(<span class="st">&quot;Orig.&quot;</span>)</span>
<span id="cb86-10"><a href="autoencoders.html#cb86-10"></a>}</span>
<span id="cb86-11"><a href="autoencoders.html#cb86-11"></a></span>
<span id="cb86-12"><a href="autoencoders.html#cb86-12"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">25</span>, <span class="dv">50</span>)) {</span>
<span id="cb86-13"><a href="autoencoders.html#cb86-13"></a>  mnist_recon &lt;-<span class="st"> </span>mnist <span class="op">%&gt;%</span></span>
<span id="cb86-14"><a href="autoencoders.html#cb86-14"></a><span class="st">      </span>prcomp <span class="op">%&gt;%</span></span>
<span id="cb86-15"><a href="autoencoders.html#cb86-15"></a><span class="st">      </span><span class="kw">predict_pca</span>(k)</span>
<span id="cb86-16"><a href="autoencoders.html#cb86-16"></a>  </span>
<span id="cb86-17"><a href="autoencoders.html#cb86-17"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>) {</span>
<span id="cb86-18"><a href="autoencoders.html#cb86-18"></a>    mnist_recon[i, ] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot_digit</span>(k)</span>
<span id="cb86-19"><a href="autoencoders.html#cb86-19"></a>  }</span>
<span id="cb86-20"><a href="autoencoders.html#cb86-20"></a>}</span></code></pre></div>
<div class="figure"><span id="fig:mnist-pca"></span>
<img src="_main_files/figure-html/mnist-pca-1.png" alt="PCA-reconstructie van 5 cijfers uit een willekeurige subset van 100 cijfers uit de MNIST dataset. Het kleine gedrukte cijfer linksboven in elke afbeelding geeft het aantal principale componenten weer waarmee de afbeelding werd gereconstrueerd." width="672" />
<p class="caption">
Figuur 9.1: PCA-reconstructie van 5 cijfers uit een willekeurige subset van 100 cijfers uit de MNIST dataset. Het kleine gedrukte cijfer linksboven in elke afbeelding geeft het aantal principale componenten weer waarmee de afbeelding werd gereconstrueerd.
</p>
</div>

<p>Naarmate er meer componenten gebruikt worden voor de reconstructie, des te beter wordt de gelijkenis met het origineel (bovenste rij in Figuur <a href="autoencoders.html#fig:mnist-pca">9.1</a>). PCA is dus in staat om een gigantische compressie door te voeren, want vergeet niet dat de originele bestanden 784 variabelen telt. Door dit terug te brengen naar 50 (compressie factor van 15.68) of zelfs minder, slaagt PCA erin de cijfers herkenbaar terug te reconstrueren.</p>
</div>
<div id="beperkingen-van-pca" class="section level2">
<h2><span class="header-section-number">9.5</span> Beperkingen van PCA</h2>
<p>PCA is een lineair systeem, en werkt niet goed wanneer er niet-lineaire verbanden bestaan onder de originele variabelen. Bedank bijvoorbeeld een afbeelding die bestaat uit concentrische cirkels. In dat geval bestaan er kwadratische verbanden tussen de variabelen en zal PCA niet goed presteren. We kunnen dan wel een polaire transformatie uitvoeren om de cirkels om te zetten naar lijnen, maar in een realistische situatie, met een complexe mix van lineaire en niet-lineaire verbanden, brengt een transformatie geen zode aan de dijk. We moeten op zoek naar een niet-lineaire compressie-techniek.</p>
</div>
<div id="de-architectuur-van-de-autoencoder" class="section level2">
<h2><span class="header-section-number">9.6</span> De Architectuur van de Autoencoder</h2>
<p>De architectuur van de autoencoder doet ons heel erg denken aan datgene de procedure die we hierboven volgden met het PCA algoritme. Alleen worden hier specifieke terminologie gebruikt. De <em>encoder</em> stelt het NN voor dat gebruikt zal worden om de oorspronkelijke data te comprimeren tot een klein aantal variabelen en de <em>decoder</em> is een NN netwerk dat net het omgekeerde zal doen. De encoder en decoder zijn in feite hetzelfde NN, t.t.z. met gespiegelde architectuur.</p>
<div class="figure"><span id="fig:autoencoder-architecture"></span>
<img src="img/autoencoder-architecture.svg" alt="De architectuur van de autoencoder. De encoder vertaald de invoer naar de embedding, een vereenvoudigde, gecomprimeerde voorstelling van de invoer-data. De decoder dient in feite om het oorspronkelijk beeld te kunnen reproduceren."  />
<p class="caption">
Figuur 9.2: De architectuur van de autoencoder. De encoder vertaald de invoer naar de embedding, een vereenvoudigde, gecomprimeerde voorstelling van de invoer-data. De decoder dient in feite om het oorspronkelijk beeld te kunnen reproduceren.
</p>
</div>

<p>De reproductie van het oorspronkelijk beeld heeft verschillende doeleinden:</p>
<ul>
<li>Het laat toe aan het NN om <em>zelf-lerend</em> te zijn. De verliesfunctie zal namelijk bestaan uit het â€˜verschilâ€™ tussen invoer en reconstructie.</li>
<li>Het laat ook toe om achteraf diagnostische statistieken te trekken zodat je bijvoorbeeld kan bepalen wat het maximum toelaatbaar verlies is in de reconstructie, wat de minimale grootte is van de embedding en bijgevolg wat de maximum haalbare graad van compressie is. Na het trainen is het echter de embedding en niet de reconstructie die je gebruikt om de analyse-pipeline mee voort te zetten.</li>
</ul>
</div>
<div id="autoencoder-op-de-mnist-dataset" class="section level2">
<h2><span class="header-section-number">9.7</span> Autoencoder op de MNIST dataset</h2>
<p>Op basis van de <a href="https://blog.keras.io/building-autoencoders-in-keras.html">blog van Layan Alabdullatef</a> kunnen we nu proberen om de bovenstaande oefening met PCA op de MNIST dataset te herhalen met een autoencoder. We beginnen met het laden van de MNIST dataset:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="autoencoders.html#cb87-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb87-2"><a href="autoencoders.html#cb87-2"></a><span class="im">import</span> keras</span>
<span id="cb87-3"><a href="autoencoders.html#cb87-3"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb87-4"><a href="autoencoders.html#cb87-4"></a><span class="im">from</span> keras.callbacks <span class="im">import</span> TensorBoard</span>
<span id="cb87-5"><a href="autoencoders.html#cb87-5"></a><span class="im">from</span> keras.datasets <span class="im">import</span> mnist</span>
<span id="cb87-6"><a href="autoencoders.html#cb87-6"></a></span>
<span id="cb87-7"><a href="autoencoders.html#cb87-7"></a>(x_train, _), (x_test, _) <span class="op">=</span> mnist.load_data()</span>
<span id="cb87-8"><a href="autoencoders.html#cb87-8"></a></span>
<span id="cb87-9"><a href="autoencoders.html#cb87-9"></a>x_train <span class="op">=</span> x_train.astype(<span class="st">&#39;float32&#39;</span>) <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb87-10"><a href="autoencoders.html#cb87-10"></a>x_test <span class="op">=</span> x_test.astype(<span class="st">&#39;float32&#39;</span>) <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb87-11"><a href="autoencoders.html#cb87-11"></a></span>
<span id="cb87-12"><a href="autoencoders.html#cb87-12"></a>x_train <span class="op">=</span> x_train.reshape((<span class="bu">len</span>(x_train), np.prod(x_train.shape[<span class="dv">1</span>:])))</span>
<span id="cb87-13"><a href="autoencoders.html#cb87-13"></a>x_test <span class="op">=</span> x_test.reshape((<span class="bu">len</span>(x_test), np.prod(x_test.shape[<span class="dv">1</span>:])))</span></code></pre></div>
<p>De afbeeldingen van 28 Ã— 28 zullen rechtstreeks als input dienen:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="autoencoders.html#cb88-1"></a>input_img <span class="op">=</span> keras.Input(shape <span class="op">=</span> (<span class="dv">784</span>, ))</span></code></pre></div>
<p>We moeten nu de grootte bepalen van de embedding. Laten we hier kiezen voor 10. Dit wil zeggen dat we de dimensionaliteit van 784 variabelen gaan terugbrengen naar 10 variabelen. Om niet te bruusk te maken en effectiever te kunnen trainen, passeren we via twee lagen, eentje van 128 nodes en de andere van 64 nodes.</p>
<p><img src="img/autoencoder-architecture2.svg" /></p>
<div class="sourceCode" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="autoencoders.html#cb89-1"></a>embedding_dim <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb89-2"><a href="autoencoders.html#cb89-2"></a></span>
<span id="cb89-3"><a href="autoencoders.html#cb89-3"></a>embedding <span class="op">=</span> layers.Dense(<span class="dv">128</span>, activation <span class="op">=</span> <span class="st">&quot;relu&quot;</span>)(input_img)</span>
<span id="cb89-4"><a href="autoencoders.html#cb89-4"></a>embedding <span class="op">=</span> layers.Dense(<span class="dv">64</span>, activation <span class="op">=</span> <span class="st">&quot;relu&quot;</span>)(embedding)</span>
<span id="cb89-5"><a href="autoencoders.html#cb89-5"></a>embedding <span class="op">=</span> layers.Dense(embedding_dim, activation <span class="op">=</span> <span class="st">&quot;relu&quot;</span>)(embedding)</span></code></pre></div>
<p>De heropbouw van de embedding naar de gereconstrueerde afbeelding door de decoder weerspiegelt de architectuur van de encoder:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="autoencoders.html#cb90-1"></a>reconstruction <span class="op">=</span> layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span> <span class="st">&quot;relu&quot;</span>)(embedding)</span>
<span id="cb90-2"><a href="autoencoders.html#cb90-2"></a>reconstruction <span class="op">=</span> layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span> <span class="st">&quot;relu&quot;</span>)(reconstruction)</span>
<span id="cb90-3"><a href="autoencoders.html#cb90-3"></a>reconstruction <span class="op">=</span> layers.Dense(<span class="dv">784</span>, activation <span class="op">=</span> <span class="st">&quot;sigmoid&quot;</span>)(reconstruction)</span></code></pre></div>
<p>Het NN kan nu worden samengesteld. We maken ook afzonderlijke modellen voor zowel de encoder als de decoder:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="autoencoders.html#cb91-1"></a>autoencoder <span class="op">=</span> keras.Model(input_img, reconstruction)</span>
<span id="cb91-2"><a href="autoencoders.html#cb91-2"></a></span>
<span id="cb91-3"><a href="autoencoders.html#cb91-3"></a>encoder <span class="op">=</span> keras.Model(input_img, embedding)</span>
<span id="cb91-4"><a href="autoencoders.html#cb91-4"></a></span>
<span id="cb91-5"><a href="autoencoders.html#cb91-5"></a>encoded_input <span class="op">=</span> keras.Input(shape <span class="op">=</span> (embedding_dim,))</span>
<span id="cb91-6"><a href="autoencoders.html#cb91-6"></a>decoder <span class="op">=</span> keras.Model(encoded_input, autoencoder.layers[<span class="op">-</span><span class="dv">1</span>](autoencoder.layers[<span class="op">-</span><span class="dv">2</span>](autoencoder.layers[<span class="op">-</span><span class="dv">3</span>](</span>
<span id="cb91-7"><a href="autoencoders.html#cb91-7"></a>  encoded_input))))</span></code></pre></div>
<p>We configureren het leeralgoritme met het <em>Adam</em> optimalisatie algoritme en met de <em>binaire cross entropy</em> als verliesfunctie.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="autoencoders.html#cb92-1"></a>autoencoder.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;binary_crossentropy&#39;</span>)</span></code></pre></div>

<div class="corollary">
<p><span id="cor:Adam" class="corollary"><strong>Nerd alert 9.1  </strong></span>Het Adam optimalisatie algoritme is een combinatie van het momentum algoritme en het RMSProp algoritme. De naam Adam is afgeleid van <em>adaptive moment estimation</em>.</p>
<p>Het momentum algoritme is dan weer afgeleid van een bal die op het grillige vlak van de verliesfunctie naar beneden rolt en daarbij een momentum heeft. Het versnelt bij steile stukken en stopt niet zomaar met rollen als het laagste punt bereikt is. Het doet dit door een <a href="https://nl.wikipedia.org/wiki/Voortschrijdend_gemiddelde">voortschrijdend gemiddelde</a> te berekenen van de gradiÃ«nten.</p>
<p>RMSProp komt van <em>Root Mean Square Propagation</em>. In dit laatste algoritme past de leersnelheid zich aan aan de kwadraten van de recente gradiÃ«nten.</p>
Behalve de leersnelheid (<span class="math inline">\(\alpha\)</span>) hangt Adam ook af van de hyperparameters <span class="math inline">\(\beta_1\)</span> en <span class="math inline">\(\beta_2\)</span>, de verval-constanten voor de L1 en L2 momenten van de gradiÃ«nten, en <span class="math inline">\(\epsilon\)</span> (epsilon; niet te verwarren met <span class="math inline">\(\varepsilon\)</span>): een klein getal om deling door nul te voorkomen.
</div>

<p>Rest ons om het NN te trainen:</p>
<p>Het resultaat is verbluffend, met slechts 10 variabelen (compressiefactor van 98.72%) kunnen de cijfers goed gereproduceerd worden:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="autoencoders.html#cb93-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">5</span>))</span>
<span id="cb93-2"><a href="autoencoders.html#cb93-2"></a></span>
<span id="cb93-3"><a href="autoencoders.html#cb93-3"></a>py<span class="op">$</span>x_test[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, ] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">apply</span>(<span class="dv">1</span>, plot_digit) -&gt;<span class="st"> </span>bin</span>
<span id="cb93-4"><a href="autoencoders.html#cb93-4"></a>py<span class="op">$</span>decoded_imgs[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, ] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">apply</span>(<span class="dv">1</span>, plot_digit) -&gt;<span class="st"> </span>bin</span></code></pre></div>
<p><img src="_main_files/figure-html/ae-result-1.png" width="672" /></p>
</div>
<div id="autoencoder-met-cnn" class="section level2">
<h2><span class="header-section-number">9.8</span> Autoencoder met CNN</h2>
<p>Niets houdt ons tegen om nu met andere type encoders en decoders te werken en omdat het in het MNIST voorbeeld om afbeeldingen gaat, kan je evengoed een convolutioneel NN gebruiken:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="autoencoders.html#cb94-1"></a>input_img <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))</span>
<span id="cb94-2"><a href="autoencoders.html#cb94-2"></a></span>
<span id="cb94-3"><a href="autoencoders.html#cb94-3"></a>emb <span class="op">=</span> layers.Conv2D(<span class="dv">16</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(input_img)</span>
<span id="cb94-4"><a href="autoencoders.html#cb94-4"></a>emb <span class="op">=</span> layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(emb)</span>
<span id="cb94-5"><a href="autoencoders.html#cb94-5"></a>emb <span class="op">=</span> layers.Conv2D(<span class="dv">8</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(emb)</span>
<span id="cb94-6"><a href="autoencoders.html#cb94-6"></a>emb <span class="op">=</span> layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(emb)</span>
<span id="cb94-7"><a href="autoencoders.html#cb94-7"></a>emb <span class="op">=</span> layers.Conv2D(<span class="dv">8</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(emb)</span>
<span id="cb94-8"><a href="autoencoders.html#cb94-8"></a>emb <span class="op">=</span> layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(emb)</span>
<span id="cb94-9"><a href="autoencoders.html#cb94-9"></a></span>
<span id="cb94-10"><a href="autoencoders.html#cb94-10"></a><span class="co"># at this point the representation is (4, 4, 8) i.e. 128-dimensional</span></span>
<span id="cb94-11"><a href="autoencoders.html#cb94-11"></a></span>
<span id="cb94-12"><a href="autoencoders.html#cb94-12"></a>rec <span class="op">=</span> layers.Conv2D(<span class="dv">8</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(emb)</span>
<span id="cb94-13"><a href="autoencoders.html#cb94-13"></a>rec <span class="op">=</span> layers.UpSampling2D((<span class="dv">2</span>, <span class="dv">2</span>))(rec)</span>
<span id="cb94-14"><a href="autoencoders.html#cb94-14"></a>rec <span class="op">=</span> layers.Conv2D(<span class="dv">8</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(rec)</span>
<span id="cb94-15"><a href="autoencoders.html#cb94-15"></a>rec <span class="op">=</span> layers.UpSampling2D((<span class="dv">2</span>, <span class="dv">2</span>))(rec)</span>
<span id="cb94-16"><a href="autoencoders.html#cb94-16"></a>rec <span class="op">=</span> layers.Conv2D(<span class="dv">16</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>)(rec)</span>
<span id="cb94-17"><a href="autoencoders.html#cb94-17"></a>rec <span class="op">=</span> layers.UpSampling2D((<span class="dv">2</span>, <span class="dv">2</span>))(rec)</span>
<span id="cb94-18"><a href="autoencoders.html#cb94-18"></a>rec <span class="op">=</span> layers.Conv2D(<span class="dv">1</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;sigmoid&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>)(rec)</span>
<span id="cb94-19"><a href="autoencoders.html#cb94-19"></a></span>
<span id="cb94-20"><a href="autoencoders.html#cb94-20"></a>autoencoder <span class="op">=</span> keras.Model(input_img, rec)</span>
<span id="cb94-21"><a href="autoencoders.html#cb94-21"></a>autoencoder.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;binary_crossentropy&#39;</span>)</span></code></pre></div>
</div>
<div id="autoencoder-als-ruis-verwijderaar" class="section level2">
<h2><span class="header-section-number">9.9</span> Autoencoder als ruis-verwijderaar</h2>
<p>Autoencoders kunnen naast het reduceren van de dimensionaliteit ook gebruikt worden om ruis te verwijderen (eng: <em>denoising</em>). Om dit te demonstreren vermenigvuldigen we de grijswaarden van de input eerst met uniform verdeelde ruis:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="autoencoders.html#cb95-1"></a>noise_factor <span class="op">=</span> <span class="fl">0.75</span></span>
<span id="cb95-2"><a href="autoencoders.html#cb95-2"></a></span>
<span id="cb95-3"><a href="autoencoders.html#cb95-3"></a>x_train_noisy <span class="op">=</span> x_train <span class="op">*</span> <span class="op">\</span></span>
<span id="cb95-4"><a href="autoencoders.html#cb95-4"></a>  np.random.uniform(high <span class="op">=</span> noise_factor, size <span class="op">=</span> x_train.shape) </span>
<span id="cb95-5"><a href="autoencoders.html#cb95-5"></a>x_test_noisy <span class="op">=</span> x_test <span class="op">*</span> <span class="op">\</span></span>
<span id="cb95-6"><a href="autoencoders.html#cb95-6"></a>  np.random.uniform(high <span class="op">=</span> noise_factor, size <span class="op">=</span> x_test.shape)</span></code></pre></div>
<p>Daarna laten we hetzelfde model nog eens lopen:</p>
<p>En we zien hoe de autoencoder in staat is om de ruis teniet te doen:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="autoencoders.html#cb96-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">5</span>))</span>
<span id="cb96-2"><a href="autoencoders.html#cb96-2"></a></span>
<span id="cb96-3"><a href="autoencoders.html#cb96-3"></a>py<span class="op">$</span>x_test_noisy[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, ] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">apply</span>(<span class="dv">1</span>, plot_digit) -&gt;<span class="st"> </span>bin</span>
<span id="cb96-4"><a href="autoencoders.html#cb96-4"></a>py<span class="op">$</span>decoded_imgs[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, ] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">apply</span>(<span class="dv">1</span>, plot_digit) -&gt;<span class="st"> </span>bin</span></code></pre></div>
<p><img src="_main_files/figure-html/ae-noisy-result-1.png" width="672" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="convolutionele-neurale-netwerken-cnn.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="trainen-en-testen.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ddhaese/machine-learning-source/09_Autoencoder.Rmd",
"text": "Bron"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
